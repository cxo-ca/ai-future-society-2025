# [13주차] 인공지능과 사회 윤리

## 1. 오늘의 키워드
- 신뢰 기반 블록체인 기술, 과연 신뢰해도 되는가?
- 인공지능과 지적재산권
- AI 창작물의 권리·책임·의무
- 학습 데이터의 윤리, 알고리즘의 윤리
- 결과물의 공정성과 편향
- 인공지능을 학습시킬 권리
- 인공지능 윤리 가이드
- 공학자를 위한 윤리

## 2. 강의 핵심 내용 요약
- 강의는 먼저 '신뢰 기반의 블록체인 기술, 정말 신뢰해도 되는가?'라는 질문으로 시작해, 기술이 약속하는 신뢰와 실제 사회에서 발생할 수 있는 문제 사이에 간극이 있다는 점을 짚었다. 기술적으로 고도의 것이라고 해서 그 위에서 돌아가는 모든 행위까지 자동으로 윤리적이거나 공정한 것은 아니라는 점을 강조했다.
- 지적재산권과 인공지능 파트에서는,  
  - AI가 만들어낸 이미지·글·음악 등 창작물의 권리가 누구에게 있는지 
  - 저작권을 주장할 수 있는 주체가 인간인지, AI 시스템을 만든 회사인지, 아니면 학습 데이터 제공자인지 등 '누구의 권리인가?'라는 질문을 던졌다.  
  - AI가 만든 결과물에 문제가 생겼을 때, 책임은 누구에게 있는지(개발자, 사용자, 서비스 제공자 등), 그리고 AI가 스스로 어떤 '의무'를 진다고 말할 수 있는지에 대한 논쟁을 소개했다.  
- 인공지능 학습과 윤리 파트에서는,  
  - 학습 데이터의 윤리: 편향된 데이터, 차별적인 표현이 포함된 데이터 등이 나중에 모델의 편향으로 이어질 수 있다는 점 
  - 알고리즘의 윤리: 설계자 의도와 다르게 특정 집단에게 불리하게 작동하는 알고리즘, 설명할 수 없는 결정 구조의 문제
  - 결과물의 공정성: 같은 조건의 사람에게 다른 결과를 주는 차별적 의사결정, 공정성을 측정하는 다양한 기준들이 서로 충돌할 수 있다는 점
  - 인공지능을 학습시킬 권리: 어떤 자료를 어디까지 학습시킬지에 대한 논의를 다루었다.  
- 인공지능 윤리 파트에서는,  
  - 윤리란 단순히 선악을 판단하는 수준을 넘어, 우리 사회에서 핵심적으로 존중되는 가치를 최대한 균형있게 존중하는 방식으로 사회적으로 수용가능한 철학적·실천적 해결책이라는 점을 짚고
  - 여러 나라와 기관에서 제시한 인공지능 윤리 가이드(투명성, 공정성, 책임성, 안전, 프라이버시 존중 등)의 공통 요소를 간단히 정리했다.  
  - 마지막으로 '이런 윤리는 공학자만 잘 지키면 되는가?'라는 질문을 던지며, 인공지능이 사회 전반에 영향을 미치는 만큼 개발자뿐 아니라 기획자, 경영자, 정책 결정자, 사용자 등 모두가 함께 고민해야 한다는 관점을 제시했다.  

## 3. 인상 깊었던 포인트
- AI 창작물의 권리·책임·의무를 따져보는 부분이 흥미로웠다. 겉으로 보기에는 멋진 그림이나 글이지만, 그 뒤에는 수많은 사람의 데이터와 모델 설계가 얽혀 있다는 점에서 '누가 진짜 주인인가'라는 질문이 가볍지 않게 느껴졌다.  
- 학습 데이터의 윤리와 결과물의 공정성을 연결해서 보니, 데이터 수집 단계의 작은 편향이 나중에 의사결정에서 큰 차별로 이어질 수 있다는 설명이 인상 깊었다. 데이터사이언티스트 입장에서 특히 깊이 생각해야 할 부분이라고 느꼈다.  
- 인공지능을 학습시킬 권리라는 표현이 새로웠다. '하고 싶으면 하면 되지'가 아니라, 누구의 데이터를 어디까지 쓸 수 있는지, 동의와 통제권은 어떻게 보장할지 등 권리의 문제로 봐야 한다는 관점이 기억에 남았다.  
- 인공지능 윤리를 단순히 개발자에게만 떠넘기는 것이 아니라, 기획·운영·정책·법·사용자까지 모두의 문제로 본다는 점이 인상적이었다. 기술만 바꿔서는 해결이 안 되고 제도와 문화까지 함께 바뀌어야 한다는 메시지가 와닿았다.  

## 4. 내 생각 / 느낀 점
- 그동안 인공지능 윤리라고 하면 거창한 철학 얘기처럼 느껴졌는데, 실제로는 데이터 수집 방식, 학습 과정, 모델 배포와 모니터링까지 내가 앞으로 실제로 하게 될 업무와 직결된 문제라는 느낌이 들었다.  
- 데이터사이언티스트를 목표로 할 때, '정확도가 잘 나오는 모델'만이 목표가 아니라 그 모델이 누구에게 어떻게 쓰이고, 누군가에게 불공정하게 작용하지는 않는지까지 생각하는 태도가 중요하다고 느꼈다.  
- 특히 헬스케어·금융·채용·교육 같은 영역에서는 모델의 결정이 사람의 삶에 직접 영향을 주기 때문에, 성능·효율보다 윤리와 책임을 우선해야 할 상황도 많을 것 같다고 생각했다.  
- 앞으로 인공지능 관련 일을 한다면, 기술 공부와 함께 윤리·법·사회적 영향에 대한 관심을 꾸준히 가져야 하고 '이 모델을 진짜 이렇게 써도 되는가?'라는 질문을 스스로에게 자주 던져봐야겠다는 다짐이 생겼다.  

## 5. 더 찾아보고 싶은 것 (데이터사이언티스트 관점)
- 각 나라나 기관에서 제시한 인공지능 윤리 가이드라인(공정성, 투명성, 책임성 등)을 비교해 보고, 실제 현장에서 데이터사이언티스트가 무엇을 해야 하는지 행동 수준으로 정리해보고 싶다.  
- 학습 데이터 편향이 실제로 어떤 차별적 결과를 낳았는지(예: 채용, 대출, 범죄 예측 시스템 등) 사례를 찾아보고, 이를 기술적으로 어떻게 완화하려 했는지 논문·블로그를 통해 공부해보고 싶다.  
- 모델의 공정성을 평가하고 개선하기 위한 지표와 기법들(예: 그룹별 성능 비교, 페어니스 관련 라이브러리 등)을 작은 예제 데이터에 적용해 보는 실습을 해보고 싶다.  
- 블록체인처럼 '신뢰를 보장한다'고 주장하는 기술들이 실제로 어떤 한계와 윤리적 문제를 갖고 있는지, 그리고 데이터사이언티스트 입장에서 이런 기술을 평가하고 설명할 때 무엇을 조심해야 하는지 정리해보고 싶다.
